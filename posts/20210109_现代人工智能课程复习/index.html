<!DOCTYPE html>
<html lang="zh">

<head>
  <title>
  现代人工智能课程复习 · 实践出真知
</title>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="color-scheme" content="light dark">




<meta name="author" content="Timothy Wu">
<meta name="description" content="中山大学研一上学期现代人工智能技术复习的相关资料，主要内容为神经网络基础知识，可能涉及到线性代数、概率论、线性模型、卷积神经网络和CV进展
距离度量，重点记忆Mahalanobis距离和Minkowski距离 过拟合 Link to heading 训练集误差减小的时候，测试集误差增大。 解决方案：正则化，给误差函数增加一个惩罚项（L1/L2）
概率论 Link to heading 全概率公式，P(A) = P(A|Bi)P(Bi) 贝叶斯公式，P(Bi|A) = P(ABi)/P(A)
贝叶斯概率 Link to heading 后验概率= 先验概率*似然函数
bootstrap，自助法，频率学派使用。假设原始数据集有N个数据，可以采取随机抽取N个点的做法来生成新的数据集（可重复，可缺失）。这样可以在多个产生的数据集中评估参数估计的结果。
高斯分布 Link to heading 一元与多元的表示
交叉验证 Link to heading 信息准则：AIC与BIC
决策论 Link to heading 或者说贝叶斯决策/贝叶斯推断
最小化错误分类率。对于二分类问题，降低错误发生的概率，即把类1分给类2与类2分给类1两个事件。 最小化期望损失。使用损失函数来量化错误分类的代价。 拒绝选项 判别器 Link to heading 概率分布 Link to heading 二项分布（伯努利分布） Link to heading E = p, V = p(1-p)
高斯分布 Link to heading 对于多元实值向量，使熵取最大值的是高斯分布
中心极限定理：
独立同分布的中心极限定理。当n个随机变量独立同分布且n足够大的时候，可以将独立同分布的随机变量之和当作正态变量。 对于要定义的高斯分布，其协方差的酥油特征值要严格大于零，不然不能被正确的归一化。如果一个或多个特征值为零，则该高斯分布将是奇异的，被限制在一个低维的子空间上。 高斯分布的局限性在于它是单峰的，因此难以逼近多峰分布。解决方法是使用混合高斯分布，使用足够多的高斯分布，并调整它们的均值和方差以及线性组合的系数，几乎可以以任意精度近似所有的连续概率密度。">
<meta name="keywords" content="blog,developer,personal">

<meta name="twitter:card" content="summary"/><meta name="twitter:title" content="现代人工智能课程复习"/>
<meta name="twitter:description" content="中山大学研一上学期现代人工智能技术复习的相关资料，主要内容为神经网络基础知识，可能涉及到线性代数、概率论、线性模型、卷积神经网络和CV进展
距离度量，重点记忆Mahalanobis距离和Minkowski距离 过拟合 Link to heading 训练集误差减小的时候，测试集误差增大。 解决方案：正则化，给误差函数增加一个惩罚项（L1/L2）
概率论 Link to heading 全概率公式，P(A) = P(A|Bi)P(Bi) 贝叶斯公式，P(Bi|A) = P(ABi)/P(A)
贝叶斯概率 Link to heading 后验概率= 先验概率*似然函数
bootstrap，自助法，频率学派使用。假设原始数据集有N个数据，可以采取随机抽取N个点的做法来生成新的数据集（可重复，可缺失）。这样可以在多个产生的数据集中评估参数估计的结果。
高斯分布 Link to heading 一元与多元的表示
交叉验证 Link to heading 信息准则：AIC与BIC
决策论 Link to heading 或者说贝叶斯决策/贝叶斯推断
最小化错误分类率。对于二分类问题，降低错误发生的概率，即把类1分给类2与类2分给类1两个事件。 最小化期望损失。使用损失函数来量化错误分类的代价。 拒绝选项 判别器 Link to heading 概率分布 Link to heading 二项分布（伯努利分布） Link to heading E = p, V = p(1-p)
高斯分布 Link to heading 对于多元实值向量，使熵取最大值的是高斯分布
中心极限定理：
独立同分布的中心极限定理。当n个随机变量独立同分布且n足够大的时候，可以将独立同分布的随机变量之和当作正态变量。 对于要定义的高斯分布，其协方差的酥油特征值要严格大于零，不然不能被正确的归一化。如果一个或多个特征值为零，则该高斯分布将是奇异的，被限制在一个低维的子空间上。 高斯分布的局限性在于它是单峰的，因此难以逼近多峰分布。解决方法是使用混合高斯分布，使用足够多的高斯分布，并调整它们的均值和方差以及线性组合的系数，几乎可以以任意精度近似所有的连续概率密度。"/>

<meta property="og:title" content="现代人工智能课程复习" />
<meta property="og:description" content="中山大学研一上学期现代人工智能技术复习的相关资料，主要内容为神经网络基础知识，可能涉及到线性代数、概率论、线性模型、卷积神经网络和CV进展
距离度量，重点记忆Mahalanobis距离和Minkowski距离 过拟合 Link to heading 训练集误差减小的时候，测试集误差增大。 解决方案：正则化，给误差函数增加一个惩罚项（L1/L2）
概率论 Link to heading 全概率公式，P(A) = P(A|Bi)P(Bi) 贝叶斯公式，P(Bi|A) = P(ABi)/P(A)
贝叶斯概率 Link to heading 后验概率= 先验概率*似然函数
bootstrap，自助法，频率学派使用。假设原始数据集有N个数据，可以采取随机抽取N个点的做法来生成新的数据集（可重复，可缺失）。这样可以在多个产生的数据集中评估参数估计的结果。
高斯分布 Link to heading 一元与多元的表示
交叉验证 Link to heading 信息准则：AIC与BIC
决策论 Link to heading 或者说贝叶斯决策/贝叶斯推断
最小化错误分类率。对于二分类问题，降低错误发生的概率，即把类1分给类2与类2分给类1两个事件。 最小化期望损失。使用损失函数来量化错误分类的代价。 拒绝选项 判别器 Link to heading 概率分布 Link to heading 二项分布（伯努利分布） Link to heading E = p, V = p(1-p)
高斯分布 Link to heading 对于多元实值向量，使熵取最大值的是高斯分布
中心极限定理：
独立同分布的中心极限定理。当n个随机变量独立同分布且n足够大的时候，可以将独立同分布的随机变量之和当作正态变量。 对于要定义的高斯分布，其协方差的酥油特征值要严格大于零，不然不能被正确的归一化。如果一个或多个特征值为零，则该高斯分布将是奇异的，被限制在一个低维的子空间上。 高斯分布的局限性在于它是单峰的，因此难以逼近多峰分布。解决方法是使用混合高斯分布，使用足够多的高斯分布，并调整它们的均值和方差以及线性组合的系数，几乎可以以任意精度近似所有的连续概率密度。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://wtysos11.github.io/posts/20210109_%E7%8E%B0%E4%BB%A3%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E8%AF%BE%E7%A8%8B%E5%A4%8D%E4%B9%A0/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-01-09T14:14:04+08:00" />
<meta property="article:modified_time" content="2024-01-21T00:00:00+00:00" />





<link rel="canonical" href="http://wtysos11.github.io/posts/20210109_%E7%8E%B0%E4%BB%A3%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E8%AF%BE%E7%A8%8B%E5%A4%8D%E4%B9%A0/">


<link rel="preload" href="/fonts/fa-brands-400.woff2" as="font" type="font/woff2" crossorigin>
<link rel="preload" href="/fonts/fa-regular-400.woff2" as="font" type="font/woff2" crossorigin>
<link rel="preload" href="/fonts/fa-solid-900.woff2" as="font" type="font/woff2" crossorigin>


  
  
  <link rel="stylesheet" href="/css/coder.min.577e3c5ead537873430da16f0964b754a120fd87c4e2203a00686e7c75b51378.css" integrity="sha256-V348Xq1TeHNDDaFvCWS3VKEg/YfE4iA6AGhufHW1E3g=" crossorigin="anonymous" media="screen" />






  
    
    
    <link rel="stylesheet" href="/css/coder-dark.min.a00e6364bacbc8266ad1cc81230774a1397198f8cfb7bcba29b7d6fcb54ce57f.css" integrity="sha256-oA5jZLrLyCZq0cyBIwd0oTlxmPjPt7y6KbfW/LVM5X8=" crossorigin="anonymous" media="screen" />
  



 




<link rel="icon" type="image/svg+xml" href="/images/favicon.svg" sizes="any">
<link rel="icon" type="image/png" href="/images/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/images/favicon-16x16.png" sizes="16x16">

<link rel="apple-touch-icon" href="/images/apple-touch-icon.png">
<link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/images/safari-pinned-tab.svg" color="#5bbad5">









</head>






<body class="preload-transitions colorscheme-auto">
  
<div class="float-container">
    <a id="dark-mode-toggle" class="colorscheme-toggle">
        <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
    </a>
</div>


  <main class="wrapper">
    <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="/">
      实践出真知
    </a>
    
      <input type="checkbox" id="menu-toggle" />
      <label class="menu-button float-right" for="menu-toggle">
        <i class="fa-solid fa-bars fa-fw" aria-hidden="true"></i>
      </label>
      <ul class="navigation-list">
        
          
            <li class="navigation-item">
              <a class="navigation-link " href="/posts/">Blog</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link " href="/tags/">Tags</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link " href="/categories/">Categories</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link " href="/series/">series</a>
            </li>
          
        
        
      </ul>
    
  </section>
</nav>


    <div class="content">
      
  <section class="container post">
    <article>
      <header>
        <div class="post-title">
          <h1 class="title">
            <a class="title-link" href="http://wtysos11.github.io/posts/20210109_%E7%8E%B0%E4%BB%A3%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E8%AF%BE%E7%A8%8B%E5%A4%8D%E4%B9%A0/">
              现代人工智能课程复习
            </a>
          </h1>
        </div>
        <div class="post-meta">
          <div class="date">
            <span class="posted-on">
              <i class="fa-solid fa-calendar" aria-hidden="true"></i>
              <time datetime="2021-01-09T14:14:04&#43;08:00">
                一月 9, 2021
              </time>
            </span>
            <span class="reading-time">
              <i class="fa-solid fa-clock" aria-hidden="true"></i>
              
            </span>
          </div>
          
          <div class="categories">
  <i class="fa-solid fa-folder" aria-hidden="true"></i>
    <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/">计算机基础</a></div>

          <div class="tags">
  <i class="fa-solid fa-tag" aria-hidden="true"></i>
    <span class="tag">
      <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/">计算机</a>
    </span>
      <span class="separator">•</span>
    <span class="tag">
      <a href="/tags/%E5%86%85%E5%AE%B9/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">内容/学习笔记</a>
    </span></div>

        </div>
      </header>

      <div class="post-content">
        
        <p>中山大学研一上学期现代人工智能技术复习的相关资料，主要内容为神经网络基础知识，可能涉及到线性代数、概率论、线性模型、卷积神经网络和CV进展</p>
<ul>
<li><a href="https://www.jianshu.com/p/74eb4044d81f"  class="external-link" target="_blank" rel="noopener">距离度量</a>，重点记忆Mahalanobis距离和Minkowski距离</li>
</ul>
<h2 id="过拟合">
  过拟合
  <a class="heading-link" href="#%e8%bf%87%e6%8b%9f%e5%90%88">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h2>
<p>训练集误差减小的时候，测试集误差增大。
解决方案：正则化，给误差函数增加一个惩罚项（L1/L2）</p>
<h2 id="概率论">
  概率论
  <a class="heading-link" href="#%e6%a6%82%e7%8e%87%e8%ae%ba">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h2>
<p>全概率公式，P(A) = P(A|Bi)<em>P(Bi)
贝叶斯公式，P(Bi|A) = P(A</em>Bi)/P(A)</p>
<h2 id="贝叶斯概率">
  贝叶斯概率
  <a class="heading-link" href="#%e8%b4%9d%e5%8f%b6%e6%96%af%e6%a6%82%e7%8e%87">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h2>
<p>后验概率= 先验概率*似然函数</p>
<p>bootstrap，自助法，频率学派使用。假设原始数据集有N个数据，可以采取随机抽取N个点的做法来生成新的数据集（可重复，可缺失）。这样可以在多个产生的数据集中评估参数估计的结果。</p>
<h2 id="高斯分布">
  高斯分布
  <a class="heading-link" href="#%e9%ab%98%e6%96%af%e5%88%86%e5%b8%83">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h2>
<p>一元与多元的表示</p>
<h2 id="交叉验证">
  交叉验证
  <a class="heading-link" href="#%e4%ba%a4%e5%8f%89%e9%aa%8c%e8%af%81">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h2>
<p>信息准则：AIC与BIC</p>
<h2 id="决策论">
  决策论
  <a class="heading-link" href="#%e5%86%b3%e7%ad%96%e8%ae%ba">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h2>
<p>或者说贝叶斯决策/贝叶斯推断</p>
<ol>
<li>最小化错误分类率。对于二分类问题，降低错误发生的概率，即把类1分给类2与类2分给类1两个事件。</li>
<li>最小化期望损失。使用损失函数来量化错误分类的代价。</li>
<li>拒绝选项</li>
</ol>
<h2 id="判别器">
  判别器
  <a class="heading-link" href="#%e5%88%a4%e5%88%ab%e5%99%a8">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h2>
<h1 id="概率分布">
  概率分布
  <a class="heading-link" href="#%e6%a6%82%e7%8e%87%e5%88%86%e5%b8%83">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h1>
<h2 id="二项分布伯努利分布">
  二项分布（伯努利分布）
  <a class="heading-link" href="#%e4%ba%8c%e9%a1%b9%e5%88%86%e5%b8%83%e4%bc%af%e5%8a%aa%e5%88%a9%e5%88%86%e5%b8%83">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h2>
<p>E = p, V = p(1-p)</p>
<h2 id="高斯分布-1">
  高斯分布
  <a class="heading-link" href="#%e9%ab%98%e6%96%af%e5%88%86%e5%b8%83-1">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h2>
<p>对于多元实值向量，使熵取最大值的是高斯分布</p>
<p>中心极限定理：</p>
<ul>
<li>独立同分布的中心极限定理。当n个随机变量独立同分布且n足够大的时候，可以将独立同分布的随机变量之和当作正态变量。</li>
</ul>
<p>对于要定义的高斯分布，其协方差的酥油特征值要严格大于零，不然不能被正确的归一化。如果一个或多个特征值为零，则该高斯分布将是奇异的，被限制在一个低维的子空间上。
高斯分布的局限性在于它是单峰的，因此难以逼近多峰分布。解决方法是使用混合高斯分布，使用足够多的高斯分布，并调整它们的均值和方差以及线性组合的系数，几乎可以以任意精度近似所有的连续概率密度。</p>
<p>共轭先验分布：在贝叶斯统计中，如果先验分布与后验分布是同一分布，则称为共轭分布。一般情况下，给定概率分布，能够寻找一个先验与似然函数共轭，从而后验分布的函数形式与先验分布相同。</p>
<p>非参数估计概率密度：Parzen窗/knn</p>
<h1 id="线性判别">
  线性判别
  <a class="heading-link" href="#%e7%ba%bf%e6%80%a7%e5%88%a4%e5%88%ab">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h1>
<p>或者降维度</p>
<h2 id="fisher线性判别函数lda">
  Fisher线性判别函数（LDA）
  <a class="heading-link" href="#fisher%e7%ba%bf%e6%80%a7%e5%88%a4%e5%88%ab%e5%87%bd%e6%95%b0lda">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h2>
<p>使得类间距离最大与类内距离最小的分类方式，损失函数为类间方差/类内方差。投影面的方向由均值的中心连线决定。</p>
<h2 id="pca">
  PCA
  <a class="heading-link" href="#pca">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h2>
<p>PCA选择投影后使得样本投影点具有最大方差的方向，假设就是方差越大，信息量越多。</p>
<p>对于无监督学习，使用PCA降维，维度可以任意。
对于有监督学习，使用LDA降维，维度只能降到k-1</p>
<h1 id="线性回归">
  线性回归
  <a class="heading-link" href="#%e7%ba%bf%e6%80%a7%e5%9b%9e%e5%bd%92">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h1>
<p>Lasso回归，相当于MSE加上L1算子
岭回归，相当于MSE加上L2算子</p>
<h2 id="生成模型与判别模型">
  生成模型与判别模型
  <a class="heading-link" href="#%e7%94%9f%e6%88%90%e6%a8%a1%e5%9e%8b%e4%b8%8e%e5%88%a4%e5%88%ab%e6%a8%a1%e5%9e%8b">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h2>
<p><img src="https://user-images.githubusercontent.com/21279827/104115670-9bb6cb00-534c-11eb-87d9-fc80aa59c2d3.jpg" alt="v2-a2e753542fc6384ee351cabdbe6dd523_r">
对机器学习的任务而言， 其目标是根据属性X预测标记Y，即求得概率P(Y|X)，在贝叶斯中这也就是后验概率</p>
<h3 id="判别模型">
  判别模型
  <a class="heading-link" href="#%e5%88%a4%e5%88%ab%e6%a8%a1%e5%9e%8b">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h3>
<p>判别模型是直接求出了一个判别边界，对没有见过的实例X就可以求出边界Y
例子：SVM模型、线性回归模型、一般的人工神经网络（多层感知机）、提升方法、条件随机场、随机森林
特点：输入属性X可以直接得到Y</p>
<h3 id="生成模型">
  生成模型
  <a class="heading-link" href="#%e7%94%9f%e6%88%90%e6%a8%a1%e5%9e%8b">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h3>
<p>生成模型需要求得P(X,Y)，即一个联合概率。对于没有见过的实例X，需要求出X与不同的标记Y之间的联合概率分布，然后取最大的那个。比如上图的右边是没有严格的判定边界的，那对于未见实例（红三角），联合概率分布大的那个类会占优。
例子：高斯混合模型、朴素贝叶斯模型、隐马尔可夫模型、VAE、GAN、受限玻尔兹曼机
特点：对于输入的X，需要求出好几个概率，选择最大的那一个。</p>
<h2 id="卷积神经网络中的参数计算">
  卷积神经网络中的参数计算
  <a class="heading-link" href="#%e5%8d%b7%e7%a7%af%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%e4%b8%ad%e7%9a%84%e5%8f%82%e6%95%b0%e8%ae%a1%e7%ae%97">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h2>
<p>不考虑通道数，对于N<em>N大小的输入，与F</em>F大小的卷积核，输出大小为(N-F)/stride+1</p>
<p>案例2，对于7<em>7的图片，3</em>3的卷积核，stride=1，补了一圈零，最后为多少？
大小应该为7<em>7，原图片补了一圈零之后等价为9</em>9，之后按照公式计算即可。</p>
<p>输入7<em>7</em>3通道，经过6个3<em>3的卷积核，输出的应该为5</em>5*6的数据。此处，卷积核默认通道数与输入数据通道数相同，图片大小按照公式计算，卷积核的数量即为输出的通道数。</p>
<p>总结
<img src="https://user-images.githubusercontent.com/21279827/104115899-2dbfd300-534f-11eb-99dc-0aa19f9d7e47.png" alt="804824-20171003232331474-1860427775"></p>

      </div>


      <footer>
        


        
        
        
        
        

        
      </footer>
    </article>

    
  </section>

    </div>

    <footer class="footer">
  <section class="container">
    ©
    
      2020 -
    
    2024
     Timothy Wu 
    ·
    
     <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> & <a href="https://github.com/luizdepra/hugo-coder/" target="_blank" rel="noopener">Coder</a>.
    
  </section>
</footer>

  </main>

  

  
  
  <script src="/js/coder.min.6ae284be93d2d19dad1f02b0039508d9aab3180a12a06dcc71b0b0ef7825a317.js" integrity="sha256-auKEvpPS0Z2tHwKwA5UI2aqzGAoSoG3McbCw73gloxc="></script>
  

  

  


  

  

  

  

  

  

  

  

  

  

  

  

  

  

  
</body>

</html>
